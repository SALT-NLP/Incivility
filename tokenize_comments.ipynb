{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently run the infereencing on remote servers, we use a Dataset module from python to store tokenized comments, which significantly speeds up the training/inferencing process. Due to the size of the unlabeled dataset, they are split by time and are stored in 6 separate pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import date\n",
    "import datetime\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '20200528_20200713_all_comments.pickle',\n",
    "    '20200713_20200813_all_comments.pickle',\n",
    "    '20200201_20200528_all_comments.pickle',\n",
    "    '20201129_20210201_all_comments.pickle',\n",
    "    '20201025_20201128_all_comments.pickle',\n",
    "    '20200813_20201025_all_comments.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12326066\n"
     ]
    }
   ],
   "source": [
    "file = files[0]\n",
    "fname = '/Users/yujia/research/stance/data/comments/{}'.format(file)\n",
    "df = pd.read_pickle(fname)\n",
    "df = df.dropna(subset=['body', 'id'])\n",
    "df = df[(df['author'] != '[deleted]') & (df['author'] != '[removed]') & (df['body'] != '[deleted]') & (df['body'] != '[removed]')]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link</th>\n",
       "      <th>score</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>vulgarity</th>\n",
       "      <th>civility</th>\n",
       "      <th>namecalling</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>demeaning</th>\n",
       "      <th>comment_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1590724419</td>\n",
       "      <td>t1_fs5o12b</td>\n",
       "      <td>t3_grqxhn</td>\n",
       "      <td>fs5xqx1</td>\n",
       "      <td>brdwatchr</td>\n",
       "      <td>Your statements were so vague that no one woul...</td>\n",
       "      <td>uspolitics</td>\n",
       "      <td>/r/uspolitics/comments/grqxhn/trump_forgets_we...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143654</td>\n",
       "      <td>0.987132</td>\n",
       "      <td>0.950770</td>\n",
       "      <td>0.040720</td>\n",
       "      <td>0.257383</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1590722281</td>\n",
       "      <td>t3_gsjyd6</td>\n",
       "      <td>t3_gsjyd6</td>\n",
       "      <td>fs5udiu</td>\n",
       "      <td>VooDooOperator</td>\n",
       "      <td>Who wrote this headline? A toaster?</td>\n",
       "      <td>uspolitics</td>\n",
       "      <td>/r/uspolitics/comments/gsjyd6/klobuchar_ate_a_...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513056</td>\n",
       "      <td>0.963877</td>\n",
       "      <td>0.125301</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1590720172</td>\n",
       "      <td>t3_gsjyd6</td>\n",
       "      <td>t3_gsjyd6</td>\n",
       "      <td>fs5qv2e</td>\n",
       "      <td>Popular-Way</td>\n",
       "      <td>Trumpie pretending so he can divide Democrats</td>\n",
       "      <td>uspolitics</td>\n",
       "      <td>/r/uspolitics/comments/gsjyd6/klobuchar_ate_a_...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078625</td>\n",
       "      <td>0.969522</td>\n",
       "      <td>0.573066</td>\n",
       "      <td>0.078954</td>\n",
       "      <td>0.053198</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1590719247</td>\n",
       "      <td>t1_fs5bha1</td>\n",
       "      <td>t3_gshwx3</td>\n",
       "      <td>fs5pad9</td>\n",
       "      <td>exkallibur</td>\n",
       "      <td>He's failed his entire life and is now President.</td>\n",
       "      <td>uspolitics</td>\n",
       "      <td>/r/uspolitics/comments/gshwx3/trumps_social_me...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>0.981085</td>\n",
       "      <td>0.938620</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1590718509</td>\n",
       "      <td>t1_fs2zwjr</td>\n",
       "      <td>t3_grqxhn</td>\n",
       "      <td>fs5o12b</td>\n",
       "      <td>droopus</td>\n",
       "      <td>Other than specificities, my statement is accu...</td>\n",
       "      <td>uspolitics</td>\n",
       "      <td>/r/uspolitics/comments/grqxhn/trump_forgets_we...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186357</td>\n",
       "      <td>0.175046</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>0.058365</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908763</th>\n",
       "      <td>1585713612</td>\n",
       "      <td>t1_fm253jk</td>\n",
       "      <td>t3_fslazd</td>\n",
       "      <td>fm35sci</td>\n",
       "      <td>Magewic</td>\n",
       "      <td>Because the alternatives are even worse. Trump...</td>\n",
       "      <td>politics</td>\n",
       "      <td>/r/politics/comments/fslazd/poll_57_of_voters_...</td>\n",
       "      <td>1</td>\n",
       "      <td>:flag-ny: New York</td>\n",
       "      <td>0.114492</td>\n",
       "      <td>0.983493</td>\n",
       "      <td>0.909322</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.034151</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908764</th>\n",
       "      <td>1585713610</td>\n",
       "      <td>t3_fsinqs</td>\n",
       "      <td>t3_fsinqs</td>\n",
       "      <td>fm35s8v</td>\n",
       "      <td>Pinkglittersparkles</td>\n",
       "      <td>Fuck the GOP.</td>\n",
       "      <td>politics</td>\n",
       "      <td>/r/politics/comments/fsinqs/marco_rubio_ripped...</td>\n",
       "      <td>1</td>\n",
       "      <td>:flag-il: Illinois</td>\n",
       "      <td>0.608223</td>\n",
       "      <td>0.978564</td>\n",
       "      <td>0.830394</td>\n",
       "      <td>0.056317</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908765</th>\n",
       "      <td>1585713610</td>\n",
       "      <td>t1_fm35jff</td>\n",
       "      <td>t3_fsrtkx</td>\n",
       "      <td>fm35s8r</td>\n",
       "      <td>DawnSennin</td>\n",
       "      <td>Fortunately enough, one doesn't have to imagin...</td>\n",
       "      <td>politics</td>\n",
       "      <td>/r/politics/comments/fsrtkx/joe_rogan_says_the...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209710</td>\n",
       "      <td>0.988254</td>\n",
       "      <td>0.958252</td>\n",
       "      <td>0.281177</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908766</th>\n",
       "      <td>1585713609</td>\n",
       "      <td>t1_fm35dt8</td>\n",
       "      <td>t3_fsr5yh</td>\n",
       "      <td>fm35s6w</td>\n",
       "      <td>PHDreseacher</td>\n",
       "      <td>They can't keep people alive without the hospi...</td>\n",
       "      <td>politics</td>\n",
       "      <td>/r/politics/comments/fsr5yh/trump_projects_up_...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160026</td>\n",
       "      <td>0.839452</td>\n",
       "      <td>0.791004</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.061701</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908767</th>\n",
       "      <td>1585713609</td>\n",
       "      <td>t3_fss1py</td>\n",
       "      <td>t3_fss1py</td>\n",
       "      <td>fm35s5p</td>\n",
       "      <td>NameRedacted123</td>\n",
       "      <td>Hot take</td>\n",
       "      <td>politics</td>\n",
       "      <td>/r/politics/comments/fss1py/trump_driven_by_th...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472683</td>\n",
       "      <td>0.347977</td>\n",
       "      <td>0.310946</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.157967</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12326066 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_utc   parent_id    link_id       id               author  \\\n",
       "0         1590724419  t1_fs5o12b  t3_grqxhn  fs5xqx1            brdwatchr   \n",
       "1         1590722281   t3_gsjyd6  t3_gsjyd6  fs5udiu       VooDooOperator   \n",
       "2         1590720172   t3_gsjyd6  t3_gsjyd6  fs5qv2e          Popular-Way   \n",
       "3         1590719247  t1_fs5bha1  t3_gshwx3  fs5pad9           exkallibur   \n",
       "4         1590718509  t1_fs2zwjr  t3_grqxhn  fs5o12b              droopus   \n",
       "...              ...         ...        ...      ...                  ...   \n",
       "3908763   1585713612  t1_fm253jk  t3_fslazd  fm35sci              Magewic   \n",
       "3908764   1585713610   t3_fsinqs  t3_fsinqs  fm35s8v  Pinkglittersparkles   \n",
       "3908765   1585713610  t1_fm35jff  t3_fsrtkx  fm35s8r           DawnSennin   \n",
       "3908766   1585713609  t1_fm35dt8  t3_fsr5yh  fm35s6w         PHDreseacher   \n",
       "3908767   1585713609   t3_fss1py  t3_fss1py  fm35s5p      NameRedacted123   \n",
       "\n",
       "                                                      body   subreddit  \\\n",
       "0        Your statements were so vague that no one woul...  uspolitics   \n",
       "1                      Who wrote this headline? A toaster?  uspolitics   \n",
       "2            Trumpie pretending so he can divide Democrats  uspolitics   \n",
       "3        He's failed his entire life and is now President.  uspolitics   \n",
       "4        Other than specificities, my statement is accu...  uspolitics   \n",
       "...                                                    ...         ...   \n",
       "3908763  Because the alternatives are even worse. Trump...    politics   \n",
       "3908764                                      Fuck the GOP.    politics   \n",
       "3908765  Fortunately enough, one doesn't have to imagin...    politics   \n",
       "3908766  They can't keep people alive without the hospi...    politics   \n",
       "3908767                                           Hot take    politics   \n",
       "\n",
       "                                                      link  score  \\\n",
       "0        /r/uspolitics/comments/grqxhn/trump_forgets_we...      1   \n",
       "1        /r/uspolitics/comments/gsjyd6/klobuchar_ate_a_...      1   \n",
       "2        /r/uspolitics/comments/gsjyd6/klobuchar_ate_a_...      1   \n",
       "3        /r/uspolitics/comments/gshwx3/trumps_social_me...      1   \n",
       "4        /r/uspolitics/comments/grqxhn/trump_forgets_we...      1   \n",
       "...                                                    ...    ...   \n",
       "3908763  /r/politics/comments/fslazd/poll_57_of_voters_...      1   \n",
       "3908764  /r/politics/comments/fsinqs/marco_rubio_ripped...      1   \n",
       "3908765  /r/politics/comments/fsrtkx/joe_rogan_says_the...      1   \n",
       "3908766  /r/politics/comments/fsr5yh/trump_projects_up_...      1   \n",
       "3908767  /r/politics/comments/fss1py/trump_driven_by_th...      1   \n",
       "\n",
       "          author_flair_text  vulgarity  civility  namecalling  stereotype  \\\n",
       "0                       NaN   0.143654  0.987132     0.950770    0.040720   \n",
       "1                       NaN   0.513056  0.963877     0.125301    0.046948   \n",
       "2                       NaN   0.078625  0.969522     0.573066    0.078954   \n",
       "3                       NaN   0.463623  0.981085     0.938620    0.035715   \n",
       "4                       NaN   0.186357  0.175046     0.122400    0.045925   \n",
       "...                     ...        ...       ...          ...         ...   \n",
       "3908763  :flag-ny: New York   0.114492  0.983493     0.909322    0.017502   \n",
       "3908764  :flag-il: Illinois   0.608223  0.978564     0.830394    0.056317   \n",
       "3908765                 NaN   0.209710  0.988254     0.958252    0.281177   \n",
       "3908766                 NaN   0.160026  0.839452     0.791004    0.045447   \n",
       "3908767                 NaN   0.472683  0.347977     0.310946    0.065951   \n",
       "\n",
       "         demeaning  comment_len  \n",
       "0         0.257383           90  \n",
       "1         0.065201            6  \n",
       "2         0.053198            7  \n",
       "3         0.084146            9  \n",
       "4         0.058365           56  \n",
       "...            ...          ...  \n",
       "3908763   0.034151           42  \n",
       "3908764   0.064667            3  \n",
       "3908765   0.042422           40  \n",
       "3908766   0.061701            9  \n",
       "3908767   0.157967            2  \n",
       "\n",
       "[12326066 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'body', 'comment_len'],\n",
       "    num_rows: 6326066\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[6000000:, :]\n",
    "# df2 = df.iloc[3000000:, :]\n",
    "\n",
    "dataset = Dataset.from_pandas(df1)\n",
    "# dataset = Dataset.load_from_disk('/Users/yujia/research/civility/datasets/20200201_20200528')\n",
    "\n",
    "dataset = dataset.remove_columns([ 'author', 'author_flair_text', '__index_level_0__', 'created_utc', 'link', 'link_id', 'parent_id', 'score', 'subreddit', 'vulgarity', 'civility', 'namecalling', 'stereotype', 'demeaning'])\n",
    "# dataset = dataset.remove_columns([ 'num_comments', 'removed_by_category', 'selftext', 'title', 'upvote_ratio', 'url'])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7fb93faa00e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429006cb80a347e58f7a0a65cc1a79e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6327 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'body', 'comment_len', 'id', 'input_ids', 'token_type_ids'],\n",
       "    num_rows: 6326066\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_dir = \"/Users/yujia/research/civility/datasets\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "dataset = dataset.map(lambda e: tokenizer(e['body'], truncation=True, padding='max_length'), batched=True)\n",
    "dataset.save_to_disk(os.path.join(datasets_dir, file+\"_second\"))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406377990"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n",
    "\n",
    "406377990"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fb1c8c08560ef10633da472fe90b901e59287299349590425902f1ab2ccdd49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
